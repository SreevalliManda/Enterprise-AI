# ðŸ§  Understanding Deep Learning, Neural Networks & LLM Architecture

## Overview
To understand how **LLMs** work, it's important to first grasp **neural networks** and **deep learning**, which in turn require a solid foundation in **machine learning**.

> While deep knowledge isnâ€™t required for most AI roles, itâ€™s essential for modifying model architectures or building models from scratch. Most companies today leverage prebuilt models, so strong **application-level knowledge** is often sufficient.

Think of it like understanding how the web works vs. using the web to build online businesses. AI is now reaching a similar level of pervasiveness.

---

## Learning Roadmaps

### Long Learning Roadmap (80â€“100+ hours)
Recommended for a **deep understanding of LLMs**:

1. **Machine Learning** â€“ Builds the foundation for deep learning  
   - *Andrew Ngâ€™s Machine Learning Course*

2. **Deep Learning** â€“ Essential for understanding neural networks  
   - *Deep Learning Specialization on Coursera*

3. **NLP Basics** â€“ Covers RNNs, transformers, and attention  
   - *Stanford CS224N - NLP with Deep Learning*

4. **LLM Architecture and Training** â€“ Covers large-scale model training and fine-tuning  
   - *Stanford CS25 - Transformers United*

5. **Building LLMs from the Ground Up** â€“ A 3-hour coding workshop

> This path is recommended for those who want to understand LLMs **under the hood**.

---

### Shorter Learning Roadmap (2â€“3 hours)
For a **practical, application-level understanding** of LLMs and transformers:

- **Jay Alammarâ€™s Illustrated Transformers** â€“ Illustrated Transformer  
- **Andrej Karpathyâ€™s Video on LLM Training** â€“ *LLMs: Training & Fine-Tuning*  
- **Illustrating Reinforcement Learning from Human Feedback (RLHF)** â€“ From HuggingFace

> This shorter path wonâ€™t make you an ML or deep learning expert but gives a solid grasp of LLMs for practical use.

---


